{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAaQnwwb0+lg3eVs8JoWe7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysg1202/automoblile/blob/main/0709_OpenCV_MOG2_%EC%B0%A8%EB%9F%89%26%EC%B0%A8%EC%84%A0%EA%B0%90%EC%A7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "배경 차분기"
      ],
      "metadata": {
        "id": "_X-HNuU1mSYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhzd1BCUek7W"
      },
      "outputs": [],
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/driving.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(f\"📌 전체 프레임 수: {total_frames}\")\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "frame_count = 0\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # 배경 차분 적용\n",
        "        fgMask = backSub.apply(frame) # 흰색 부분은 움직임이 있는 부분, 검정색 부분은 배경\n",
        "\n",
        "        # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "        if frame_count % 30 == 0:   # 30초마다 1프레임\n",
        "            # 결과를 나란히 표시\n",
        "            combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "            cv2_imshow(combined)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        # 100프레임 정도만 처리 (테스트용)\n",
        "        if frame_count > 100:\n",
        "            break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "# cap.release() # 안하면 파일이 \"사용중\" 상태\n",
        "# print(\"처리 완료!\")\n",
        "\n",
        "finally:\n",
        "    # 항상 실행됨\n",
        "    cap.release()\n",
        "    # cv2.destroyAllWindows()\n",
        "    print(\"자원 해제 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "노이즈 제거 기능 추가"
      ],
      "metadata": {
        "id": "XyWNVUSmmNoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/driving.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # 노이즈 제거 (모폴로지 연산)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)) # 연산 모양과 크기 결정 (여기선 타원형 3x3)\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)  # 작은 흰 점(노이즈) 제거\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)  # 구멍 메우기\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 10 == 0:   # 10초마다 1프레임\n",
        "        # 결과를 나란히 표시\n",
        "        combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "print(\"처리 완료!\")"
      ],
      "metadata": {
        "id": "NHzuRHyXmPkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "바운딩 박스 추가"
      ],
      "metadata": {
        "id": "6Lvv_T6In1hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/driving.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # 노이즈 제거 (모폴로지 연산)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)) # 연산 모양과 크기 결정 (여기선 타원형 3x3)\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)  # 작은 흰 점(노이즈) 제거\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)  # 구멍 메우기\n",
        "\n",
        "    # 윤곽선 검출 및 바운딩 박스\n",
        "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 바운딩 박스를 그릴 프레임 복사\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    for contour in contours:\n",
        "        # 너무 작은 영역은 제외 (차량이 아닐 가능성 높음)\n",
        "        if cv2.contourArea(contour) > 3000:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 10 == 0:   # 10초마다 1프레임\n",
        "        # 결과를 나란히 표시\n",
        "        combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "print(\"처리 완료!\")"
      ],
      "metadata": {
        "id": "ARFFa2l3n8Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "종횡비 추가 (아직안함)"
      ],
      "metadata": {
        "id": "CJv1-0FKpXkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/driving.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "    # 노이즈 제거 (모폴로지 연산)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)) # 연산 모양과 크기 결정 (여기선 타원형 3x3)\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)  # 작은 흰 점(노이즈) 제거\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)  # 구멍 메우기\n",
        "\n",
        "    # 윤곽선 검출 및 바운딩 박스\n",
        "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 바운딩 박스를 그릴 프레임 복사\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    for contour in contours:\n",
        "        # 너무 작은 영역은 제외 (차량이 아닐 가능성 높음)\n",
        "        if cv2.contourArea(contour) > 4000:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 10 == 0:   # 10초마다 1프레임\n",
        "        # 결과를 나란히 표시\n",
        "        #combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR))) # 수정\n",
        "        combined = np.hstack((result_frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "print(\"처리 완료!\")"
      ],
      "metadata": {
        "id": "WPLEBHDmpbP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROI 추가"
      ],
      "metadata": {
        "id": "hvrr9_oktDPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 기본 MOG2 차량 감지 코드\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 동영상 파일 열기 (코랩에서는 업로드한 파일 경로 사용)\n",
        "cap = cv2.VideoCapture('/content/driving.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "\n",
        "# MOG2 배경 차분기 생성\n",
        "backSub = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "# ROI 설정 (도로 영역만 분석) - 좌표는 영상에 맞게 조정 필요\n",
        "def create_roi_mask(frame):\n",
        "    height, width = frame.shape[:2] # (높이, 너비, 채널) → 앞의 두 값만 사용\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    # 도로 영역을 다각형으로 설정 (예시 - 실제 영상에 맞게 조정)\n",
        "    roi_points = np.array([\n",
        "        [0, height//2],           # 왼쪽 중간\n",
        "        [width, height//2],       # 오른쪽 중간\n",
        "        [width, height],          # 오른쪽 아래\n",
        "        [0, height]               # 왼쪽 아래\n",
        "    ], np.int32)\n",
        "\n",
        "    cv2.fillPoly(mask, [roi_points], 255) # 지정된 다각형 영역을 **흰색(255)**으로 채움\n",
        "    return mask\n",
        "\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 배경 차분 적용\n",
        "    fgMask = backSub.apply(frame)\n",
        "\n",
        "     # ROI 마스크 생성 및 적용\n",
        "    roi_mask = create_roi_mask(frame)\n",
        "    fgMask = cv2.bitwise_and(fgMask, roi_mask)  # ROI 영역만 남김\n",
        "\n",
        "\n",
        "    # 노이즈 제거 (모폴로지 연산)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)) # 연산 모양과 크기 결정 (여기선 타원형 3x3)\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)  # 작은 흰 점(노이즈) 제거\n",
        "    fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)  # 구멍 메우기\n",
        "\n",
        "    # 윤곽선 검출 및 바운딩 박스\n",
        "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # 바운딩 박스를 그릴 프레임 복사\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    for contour in contours:\n",
        "        # 너무 작은 영역은 제외 (차량이 아닐 가능성 높음)\n",
        "        if cv2.contourArea(contour) > 4000:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    # 매 30프레임마다 결과 출력 (너무 많은 출력 방지)\n",
        "    if frame_count % 10 == 0:   # 10초마다 1프레임\n",
        "        # 결과를 나란히 표시\n",
        "        #combined = np.hstack((frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR))) # 수정1\n",
        "        combined = np.hstack((result_frame, cv2.cvtColor(fgMask, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 정도만 처리 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "print(\"처리 완료!\")"
      ],
      "metadata": {
        "id": "Wem9G82VtEnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사다리꼴 ROI로 변경, 최종 종합"
      ],
      "metadata": {
        "id": "EhJDALuCyPX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 동영상 파일 열기\n",
        "cap = cv2.VideoCapture('/content/driving.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "# 차선 검출을 위한 ROI 설정\n",
        "def create_lane_roi(frame):\n",
        "    height, width = frame.shape[:2]\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    #offset = 60\n",
        "\n",
        "    roi_points = np.array([\n",
        "    [width//4 - 80, height],        # 왼쪽 아래 (중앙 기준 좌측)\n",
        "    [width//2 - 10, height//2 +60],  # 왼쪽 위\n",
        "    [width//2 + 170, height//2 + 60],  # 오른쪽 위\n",
        "    [width*3//4 + 250, height]         # 오른쪽 아래 (중앙 기준 우측)\n",
        "], np.int32)\n",
        "\n",
        "\n",
        "\n",
        "    cv2.fillPoly(mask, [roi_points], 255)\n",
        "    return mask, roi_points\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 그레이스케일 변환\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 가우시안 블러로 노이즈 제거\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Canny 에지 검출\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "    # ROI 적용\n",
        "    roi_mask, roi_points = create_lane_roi(frame)\n",
        "    masked_edges = cv2.bitwise_and(edges, roi_mask)\n",
        "\n",
        "    # 결과 프레임 복사\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    cv2.polylines(result_frame, [roi_points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "\n",
        "    # 매 30프레임마다 결과 출력\n",
        "    if frame_count % 10 == 0:\n",
        "        # 결과를 나란히 표시 (원본 + 에지)\n",
        "        combined = np.hstack((result_frame, cv2.cvtColor(masked_edges, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 후 종료 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "UuBUP-BBySlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "차선 검출"
      ],
      "metadata": {
        "id": "ZgKyYISnA_GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 동영상 파일 열기\n",
        "cap = cv2.VideoCapture('/content/driving.mp4')  # 파일 경로 수정 필요\n",
        "\n",
        "# 차선 검출을 위한 ROI 설정\n",
        "def create_lane_roi(frame):\n",
        "    height, width = frame.shape[:2]\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    # 사다리꼴 모양의 ROI (차선이 있는 도로 영역)\n",
        "    roi_points = np.array([\n",
        "    [width//4 - 80, height],        # 왼쪽 아래 (중앙 기준 좌측)\n",
        "    [width//2 - 10, height//2 +60],  # 왼쪽 위\n",
        "    [width//2 + 170, height//2 + 60],  # 오른쪽 위\n",
        "    [width*3//4 + 250, height]         # 오른쪽 아래 (중앙 기준 우측)\n",
        "], np.int32)\n",
        "\n",
        "\n",
        "    cv2.fillPoly(mask, [roi_points], 255)\n",
        "    return mask\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 그레이스케일 변환\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 가우시안 블러로 노이즈 제거\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Canny 에지 검출\n",
        "    edges = cv2.Canny(blur, 20, 120)\n",
        "\n",
        "    # ROI 적용\n",
        "    roi_mask = create_lane_roi(frame)\n",
        "    masked_edges = cv2.bitwise_and(edges, roi_mask)\n",
        "\n",
        "    # Hough 변환으로 직선 검출\n",
        "    lines = cv2.HoughLinesP(masked_edges, 1, np.pi/180, threshold=30,\n",
        "                           minLineLength=50, maxLineGap=70)\n",
        "\n",
        "    # 결과 프레임들 복사\n",
        "    result_frame = frame.copy()\n",
        "    lane_frame = frame.copy()\n",
        "\n",
        "    # 차선 분류를 위한 리스트\n",
        "    left_lines = []\n",
        "    right_lines = []\n",
        "\n",
        "    # 검출된 차선을 좌/우로 분류\n",
        "    if lines is not None:\n",
        "        img_center = frame.shape[1] // 2  # 화면 중앙\n",
        "\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "\n",
        "            # 기울기 계산 (수직선 제외)\n",
        "            if x2 - x1 != 0:\n",
        "                slope = (y2 - y1) / (x2 - x1)\n",
        "\n",
        "                # 기울기와 위치로 좌/우 차선 분류\n",
        "                if slope < -0.3 and x1 < img_center:  # 왼쪽 차선 (음의 기울기)\n",
        "                    left_lines.append([x1, y1, x2, y2])\n",
        "                elif slope > 0.3 and x1 > img_center:  # 오른쪽 차선 (양의 기울기)\n",
        "                    right_lines.append([x1, y1, x2, y2])\n",
        "\n",
        "    # 차선 연결 함수\n",
        "    def connect_lane_segments(lines, frame_height):\n",
        "        if not lines:\n",
        "            return None\n",
        "\n",
        "        # 모든 점들을 수집\n",
        "        points = []\n",
        "        for x1, y1, x2, y2 in lines:\n",
        "            points.extend([(x1, y1), (x2, y2)])\n",
        "\n",
        "        if len(points) < 2:\n",
        "            return None\n",
        "\n",
        "        # 최소자승법으로 직선 피팅\n",
        "        points = np.array(points)\n",
        "        x_coords = points[:, 0]\n",
        "        y_coords = points[:, 1]\n",
        "\n",
        "        # 1차 다항식 피팅\n",
        "        coeffs = np.polyfit(y_coords, x_coords, 1)\n",
        "\n",
        "        # 화면 상하단에서의 x 좌표 계산\n",
        "        y_top = frame_height // 2\n",
        "        y_bottom = frame_height\n",
        "        x_top = int(coeffs[0] * y_top + coeffs[1])\n",
        "        x_bottom = int(coeffs[0] * y_bottom + coeffs[1])\n",
        "\n",
        "        return [x_top, y_top, x_bottom, y_bottom]\n",
        "\n",
        "    # 좌측/우측 차선 연결\n",
        "    left_lane = connect_lane_segments(left_lines, frame.shape[0])\n",
        "    right_lane = connect_lane_segments(right_lines, frame.shape[0])\n",
        "\n",
        "    # 연결된 차선 그리기\n",
        "    if left_lane:\n",
        "        cv2.line(lane_frame, (left_lane[0], left_lane[1]),\n",
        "                (left_lane[2], left_lane[3]), (0, 255, 0), 5)  # 녹색 왼쪽 차선\n",
        "        cv2.putText(lane_frame, \"LEFT\", (left_lane[0]-30, left_lane[1]-10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "    if right_lane:\n",
        "        cv2.line(lane_frame, (right_lane[0], right_lane[1]),\n",
        "                (right_lane[2], right_lane[3]), (255, 0, 0), 5)  # 파란색 오른쪽 차선\n",
        "        cv2.putText(lane_frame, \"RIGHT\", (right_lane[0]+10, right_lane[1]-10),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "\n",
        "    # ROI 영역을 시각화 (사다리꼴 모양 표시)\n",
        "    roi_points = np.array([\n",
        "        [frame.shape[1]//4, frame.shape[0]],        # 왼쪽 아래\n",
        "        [frame.shape[1]*7//10, frame.shape[0]*4//5], # 왼쪽 위\n",
        "        [frame.shape[1]*6//8, frame.shape[0]*3//5], # 오른쪽 위\n",
        "        [frame.shape[1]*9//10, frame.shape[0]]      # 오른쪽 아래\n",
        "    ], np.int32)\n",
        "\n",
        "    cv2.polylines(result_frame, [roi_points], True, (255, 0, 0), 2)  # 파란색 사다리꼴\n",
        "\n",
        "    # 매 30프레임마다 결과 출력\n",
        "    if frame_count % 10 == 0:\n",
        "        # 영어 라벨 추가\n",
        "        cv2.putText(result_frame, \"Original + ROI\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        edge_display = cv2.cvtColor(masked_edges, cv2.COLOR_GRAY2BGR)\n",
        "        cv2.putText(edge_display, \"Canny Edge Detection\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.putText(lane_frame, \"Lane Detection Result\", (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        # 3개 화면을 나란히 표시\n",
        "        combined = np.hstack((result_frame, edge_display, lane_frame))\n",
        "        cv2_imshow(combined)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # 100프레임 후 종료 (테스트용)\n",
        "    if frame_count > 100:\n",
        "        break\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "print(\"차선 검출 처리 완료!\")"
      ],
      "metadata": {
        "id": "6Rdb0ic9BA4I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}